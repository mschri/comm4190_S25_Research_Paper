{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a2195c0-dfa1-4865-bb5b-fcbbee9fb34d",
   "metadata": {},
   "source": [
    "Miranda Schriver\n",
    "\n",
    "Comm 4190 Research Paper\n",
    "\n",
    "## AI & Political Messaging\n",
    "\n",
    "<img src=\"img1.jpeg\" width=\"65%\"/>\n",
    "\n",
    "### Introduction\n",
    "\n",
    "Like a number of things AI has touched and changed forever, another domain that’s seen a significant degree of influence is that of political messaging and campaigning. Countless articles have surfaced since AI and large language models have skyrocketed in daily use, many of which have settled in their deliberations on the fact that the negative implications in this case may unfortunately outweigh the positive. Of course, we are still in a relatively early stage of AI usage and are currently amidst the process of finding out exactly how this technology will shape various aspects of our lives. However, even just a quick web search on the topic of “AI and political messaging” offers a rather pessimistic outlook regarding its relationship with politically associated mass communication.\n",
    "\n",
    "In short, the subject of this paper will examine how AI driven tools like large language models, namely the most popular ones we know and love like ChatGPT, Claude, Llama and so forth, are used within the communicative context of political messaging and media content. The implications of this interaction will be considered within a broad array of related contexts, for instance in political campaigning by candidates themselves, or by third party supporters of these political actors, as well as how LLMs might affect the consumption of political content by voters and constituents. This will be accomplished with the synthesis of perspectives on the topic via news article debates and scholarly literature, along with primary observations from probing the models themselves and analyzing their responses. Ultimately, all of this information will be considered to find out how AI and political messaging may work together to either forward or degrade foundational pieces of a democratic society.\n",
    "\n",
    "### The verdict of the News-scape:\n",
    "\n",
    "The assessment of LLM use within the political sphere began with an article that described AI tools as a “dual-edge[d]” sword (Singh, 2024). Published by the Fair Observer, the author concludes generally speaking that while artificial intelligence may be beneficial to democratic processes, the associated risks are also incredibly glaring. Naming only a few positives including its ability to provide greater access to information and therefore increase political engagement, its algorithms contribute to the rise of echo chambers, spread of misinformation, and even offers the potential to manipulate election results (Singh, 2024). For example, one article cites the profound effect of digital propaganda (i.e. deep fakes and robocalls) proliferation through its highly effective targeted messaging scheme (Emory, 2024). With this, the potential to affect political opinion and election outcomes by even just average content creators calls for a serious consideration in moderating the use of AI and LLMs within political messaging. Moreover with the current absence of federal regulation with AI and LLM use in political campaigns, political material may see a saturation of false content which serves to undermine public trust as well (GW Media Relations, 2024). In other words, fears of AI and LLM abuse comes from both individual, private entities and in campaigns who have the ability through this technology to “manufacture their own realities” (Emory, 2024).\n",
    "\n",
    "Other articles continue to echo this sentiment, describing AI as an engine for “destabiliz[ing] democracies in unforeseen ways” (Csernatoni, 2024). Again, these online writers are concerned with the novel ability of these models to generate synthetic voices, create hyper-realistic images and videos, and manipulate vast amounts of data, as this can be seen as opportunities for abuse by ill-intentioned actors (from political opponents to foreign adversaries to everyday people) to manipulate public perception on a grand scale. In the case that such malicious actors start to overpower the democratic process by negatively influencing constituent discourse in this way, the article names what could become a broader trend of eroding democratic safeguards through its impact on the integrity of organic formation of public opinion in the face of lessened conversational diversity. As a result, an unsurprising rise in “digital authoritarianism” embracing mass AI surveillance appears to be the most apt solution by some countries, given the increasingly higher stakes of liberal LLM use especially within American society (Shabaz, 2025). And with that, another facet of this issue arises: the abuse of AI by individuals attempting to sway political opinion might force the hand of more powerful governments to take away free LLM use, thereby contributing to the wearing down of democratization.\n",
    "\t\n",
    "What’s also worth mentioning as a separate feature attached to some of these arguments is the idea of privacy concerns on a larger, global scale. Iin countries where weaker forms of democratic government exist and have implemented AI and LLM public use, more powerful autocratic governments can weaponize these mass data processing technologies in the event that effective safeguards against digital privacy risks are lacking in these more vulnerable states (Recanati & Kerley, 2024; Khaled, 2025). This demonstrates another negative context by which leveraging of LLMs and AI tools by high-end entities can also occur against a political backdrop, and which have severe consequences for the fate of democracy in a broader international scope. It’s therefore in the interest of policymakers domestically and globally to ensure transparency and accountability is maintained by governmental and private entities alike that wield this technology.\n",
    "\n",
    "### Scholarly Opinion: A Literature Review\n",
    "\n",
    "Having named some of the prevailing arguments within newsroom deliberations regarding this topic, we now turn how scholars may be viewing LLM use in political messaging and other related contexts. One of the strongest, most flagrant manifestations of this interaction sees increased polarization especially within the United States where polarization is already rampant. Expanding on the notion of echo chambers referenced earlier, the combination of LLM-curated content and AI-driven algorithmic recommendations within social media platforms creates these filter bubbles that trap users within a particular content feed that tend to espouse certain political notions (Acemoglu et al., 2025; Goswami, 2025). Defining the notion of “generated memetic weaponization” as the mediation of content by AI through customized, generated images, another study describes this encapsulating process wherein partisan political information in the form of highly effective and absurd political content (i.e. “memes”) optimizes user engagement with a social media platform and limits users to the exposure to counter-attitudinal information (Chang et al., 2024). Consequently, these platforms encourage polarization because users aren’t given opportunities onced trapped in these bubbles to enrich their political perspectives, so they become pigeon-holed into particular political sects that tend to antagonize outgroup beliefs (Goswami, 2025). \n",
    "Furthermore, one of the studies referenced above (Acemoglu et al., 2025) found that these polarizing effects extend to the parties themselves. This occurs because they respond to and capitalize on the divisive trend by pushing targeted, partisan digital ads to monetize their party platforms. In turn, this fuels the popularity of such polarizing content and therefore a positive feedback mechanism ensues. With parties being incentivized in this way to forward polarizing content because it empowers their own platforms, content of this nature continues to grow tenfold and unassuming constituencies are left hopeless to know otherwise. This ultimately demonstrates yet another way in which AI and LLMs are being leveraged in political messaging contexts towards unproductive means, as its for the sake of forwarding particular partisan aims. \n",
    "\n",
    "Looking beyond the scope of just American politics, a study on UK general elections analyzing AI-enabled influence foresees its influence being exacerbated and growing exponentially with more and more of its use (Stockwell et al., 2024). While the study surfaced nothing new with regards to the current overall impacts on election cycles, it identifies three categories of threats that hurt the process: campaign threats, information threats, and infrastructure. Through its outlining of a more formal means by which we assess the kinds of damaging content and look to find solutions that enhance election resilience, this article continued to establish the many problems currently associated with AI- and LLM-driven political messaging.\n",
    "\n",
    "### ChatGPT as a News reporter\n",
    "\n",
    "<img src=\"img2.png\" width=\"65%\"/>\n",
    "\n",
    "To demonstrate some of the extent to which this political polarization can take hold, I engaged with ChatGPT in a conversation in which I asked it to describe certain political events. I prompted two different questions with each taking the role of a political side (by proxy of the specified news source; left and right leaning sources), totalling in at four questions.\n",
    "\n",
    "All of the questions followed a similar structure, starting with: “You are a high-profile news reporter from ____;” (filled in with either Fox-right, or CNN-left), and following the semi-colon I asked it to describe different, notably charged political events. For example, the first question was with respect to describing this past 2024 election cycle and results. The outputs for both roles were long, but here were some of the key features. \n",
    "\n",
    ">For the Fox role, the output included the following:\n",
    "* “In a historic political comeback, former President Donald Trump secured a non-consecutive second term by defeating Vice President Kamala Harris.”\n",
    "* “Kamala Harris's campaign suffered from low voter turnout in key Democratic strongholds” (this subsection was also titled, “Democratic Turnout: A Party's Struggle”)\n",
    "* Another subsection was titled the following: “Congressional Shifts: Republican Resurgence”\n",
    "\n",
    "> For CNN:\n",
    "\n",
    "* \"The Democratic campaign faced significant challenges when President Joe Biden withdrew from the race in July 2024, following a widely criticized debate performance against Trump.”\n",
    "* “Biden's performance was criticized for lacking clarity and energy, raising concerns about his age and fitness for office.” (subsection was titled: “Debates and Media Reactions”)\n",
    "\n",
    "To note just a few brief observations and differences, the first report was written favorably towards Trump and not so much for the Democratic side; between emphasizing Biden’s shortcomings and age limitations, describing Trump’s re-election as a “historic comeback,” and highlighting the struggles of Kamala’s campaign, the information presented in this report definitely included some key differences that point towards a non-neutral reporting on both ends.\n",
    "\n",
    "I won’t continue to exhaust some of the obvious differences here between how the priming of the news source effects the report, but in an effort not to neglect the other part of this mini-experiment, here were some of the findings:\n",
    "\n",
    "* The report began by introducing the events as one that started as a “political rally” for Trump; by contrast in the second report, it started with the following: “Reporting from CNN on one of the most unprecedented days in modern U.S. history.”\n",
    "* The second report also highlighted how the demonstration spiraled into, “ a full-scale breach of the Capitol grounds,” emphasizing the grave democratic implications of the events.\n",
    "\n",
    "These were a few key findings, but once again the trends are fairly clear. Priming can definitely influence the output even when asked to simply report on the events as it is. This was only a minor exercise in the differences that arise depending on how you prompt an LLM on news-related information, but the bigger implication is this: users who may lean one particular way politically will continue to consume information that feeds into their confirmation bias because their initial inputs and prompts may already include some bias. Therefore, this illustrates the start of a vicious cycle in which resentment festers, neutral information becomes more and more elusive–especially as people increasingly rely on this technology, and polarization grows tenfold.\n",
    "\n",
    "### Some of the Pros:\n",
    "\n",
    "With all of that being said, it is worth at least briefly noting the possible benefits and positives associated with LLM use in this realm. For one, some of the previously referenced articles note the technology allows for more efficient and far-reaching messaging, as well as creative ways to reach a broader array of voters. Especially for less-resourced campaigns, this can empower their platforms by offering a low-cost, user-friendly means of disseminating their messages and perhaps even rival more sophisticated, bigger-budget campaigns (LaChapelle & Tucker, 2023).\n",
    "\n",
    "Further, for the same reasons described above AI can on the other hand improve democratic discourse. A study found in a conversation between two participants that if one had access to an LLM-based chat assistant that produced recommendations for guiding discussion, this increased their partner’s reported quality of conversation (Argyle et al., 2023). Moreover, both participants increased their willingness to offer each other space to express and advocate their opinions despite the fact that their views remained unchanged. Ultimately, these findings attest to at worst a neutral effect of AI in spiraling social division further, and at best can perhaps do the opposite by fostering diverse political conversation. So, if nothing else, this article also serves as a counter to the argument that AI aides in swinging political opinions deeper one way or another.\n",
    "\n",
    "In a separate study by the same publisher as the above article, researchers also used LLMs productively for testing various theories of persuasion. In all, they found that LLMs were about equally persuasive across different conditions of persuasion, and at the very least LLM-generated messages with “micro-targeted customization” aren’t clearly more persuasive than a generic message (Argyle, 2025). Once again, this points to the more complex relationship between LLM-directed political messaging and internalization of these messages, which counters the black-and-white perception AI contributes in a purely negative capacity. And, this study illustrates the productive ways in which LLM usage can contribute to research purposes.\n",
    "\n",
    "There’s also an argument that states AI and LLMs represent just another medium for rhetorical persuasion and disseminating information in line with other forms of technology we’ve already seen. From the GW School of Media and Public Affairs, director Peter Lodge for instance emphasizes that, “there aren’t AI ethics that different from everybody else’s ethics…that’s true with AI, with mail, with television, with speeches” (GW Media Relations, 2024). His concluding sentiment following these remarks is that we aren’t truly asking questions any different from what we have been asking with rhetoric and persuasion for centuries, and for that reason we shouldn’t necessarily deem AI as some grand, unimaginably new source of threat.\n",
    "\n",
    "### Conclusion\n",
    "The conversation surrounding LLM and AI use within this domain is clearly ongoing as we can see. Nevertheless, this paper has also thoroughly established the nature of the conversation as a fearful one. A considerable amount of discourse and scholarly evidence points to ways in which AI usage may prove dangerous, which therefore warrants an even deeper consideration of mitigation and regulation efforts to curb these effects.\n",
    "\n",
    "To reiterate, a major theme throughout analysis of this discourse concerns degradation of the democratic process and its governance that comes with obscuring citizens’ abilities to make informed decisions. As it stands, legislation like that of the European Freedom Act oversees acknowledges users’ rights to personalized platforms. However, the cabinet behind its institution simultaneously expresses significant concern in its hindrance of constructive political discourse, and highlights the need for safeguards that ensure users have greater access to more diverse political content (Muto, 2025). We have yet to see formal legislative measures preventing the mechanisms that enable echo chambers, but the article (Muto) describing the aforementioned European landscape reconciling with this new form of media use cites an honest attempt to begin doing so; the Munich Security Security Conference held in February 2024 outlined eight concrete commitments to combat online content that undermines the political process, including the implementation of technology within these platforms that checks for deceptive information, a system of user notification to better inform the constituency, and the promotion of an intersectoral response to deceptive election content. \n",
    "\n",
    "Ultimately, the majority of these articles seeking solutions in this area stress the importance of promoting digital literacy, so that daily use by average citizens involves more informed consumption and internalization of media messaging (Singh, 2024; Goswami, 2025). If we learn to be more conscious of what we are reading and watching more frequently, we avoid falling into the trap of buying into content that further divides. Because it is a mostly subconscious process, the ease with which we find ourselves being increasingly fractured along political lines has shown to have implications beyond mere resentment for the other side bred out of bitter squabbles; the erosion of democratic processes positioned by our mindless consumption habits becomes at stake. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7530003-ba7f-454e-9a97-8b96836ffb67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
